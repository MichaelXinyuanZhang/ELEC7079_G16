{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663d969",
   "metadata": {},
   "source": [
    "# Interval estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812471c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the Gaussian distribution\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "\n",
    "for NUM_SAMPLE in [10, 50, 100, 1000, 10000]:\n",
    "\n",
    "    # Create a random number generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # Generate normally distributed random numbers\n",
    "    gaussian_numbers = rng.normal(mean, std_dev, NUM_SAMPLE)\n",
    "\n",
    "    # Round the numbers to integers\n",
    "    data_sample = np.round(gaussian_numbers).astype(int)\n",
    "\n",
    "    sample_mean = np.mean(data_sample)\n",
    "    sample_std = np.std(data_sample)\n",
    "\n",
    "    # Define the confidence level and calculate the margin of error\n",
    "    confidence_level = 0.95\n",
    "    z_score = st.norm.ppf(confidence_level + (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_score * (sample_mean / sample_std)\n",
    "\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    print(\"Num.Sample: {}, Confidence Interval ({}%): ({}, {})\".format(NUM_SAMPLE, confidence_level * 100, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9aee3a",
   "metadata": {},
   "source": [
    "## With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the Gaussian distribution\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "\n",
    "noise_mean = 0\n",
    "noise_std_dev = 5\n",
    "\n",
    "for NUM_SAMPLE in [10, 50, 100, 1000, 10000, 100000]:\n",
    "\n",
    "    # Create a random number generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # Generate normally distributed random numbers\n",
    "    gaussian_numbers = rng.normal(mean, std_dev, NUM_SAMPLE)\n",
    "    \n",
    "    gaussian_noise = rng.normal(noise_mean, noise_std_dev, NUM_SAMPLE)\n",
    "\n",
    "    # Round the numbers to integers\n",
    "    data_sample = np.round(gaussian_numbers+gaussian_noise).astype(int)\n",
    "\n",
    "    sample_mean = np.mean(data_sample)\n",
    "    sample_std = np.std(data_sample)\n",
    "\n",
    "    # Define the confidence level and calculate the margin of error\n",
    "    confidence_level = 0.95\n",
    "    z_score = st.norm.ppf(confidence_level + (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_score * (sample_mean / sample_std)\n",
    "\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    print(\"Num.Sample: {}, Confidence Interval ({}%): ({:.4f}, {:.4f})\".format(NUM_SAMPLE, confidence_level * 100, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_corr, _ = st.pearsonr(gaussian_noise, gaussian_numbers)\n",
    "print(f\"Series correlation:{ser_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05018570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faf08a03",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ec1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the Gaussian distribution\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "\n",
    "noise_mean = 0\n",
    "noise_std_dev = 5\n",
    "\n",
    "for NUM_SAMPLE in [10, 50, 100, 1000, 10000, 50000]:\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Create a random number generator\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # Generate normally distributed random numbers\n",
    "    gaussian_numbers = rng.normal(mean, std_dev, NUM_SAMPLE)\n",
    "    \n",
    "    gaussian_noise = rng.normal(noise_mean, noise_std_dev, NUM_SAMPLE)\n",
    "    \n",
    "    # Verify the correlation using numpy\n",
    "    computed_correlation = np.corrcoef(gaussian_numbers, gaussian_noise)[0, 1]\n",
    "    print(f\"Computed correlation:{computed_correlation:.4f}\")\n",
    "\n",
    "    # Round the numbers to integers\n",
    "    data_sample = np.round(gaussian_numbers+gaussian_noise).astype(int)\n",
    "\n",
    "    sample_mean = np.mean(data_sample)\n",
    "    sample_std = np.std(data_sample)\n",
    "\n",
    "    # Define the confidence level and calculate the margin of error\n",
    "    confidence_level = 0.95\n",
    "    z_score = st.norm.ppf(confidence_level + (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_score * (sample_mean / sample_std)\n",
    "\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    print(\"Num.Sample: {}, Confidence Interval ({}%): ({:.4f}, {:.4f})\".format(NUM_SAMPLE, confidence_level * 100, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the Gaussian distribution\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "\n",
    "noise_mean = 0\n",
    "noise_std_dev = 5\n",
    "\n",
    "# Set the desired correlation\n",
    "target_correlation = 0.5\n",
    "\n",
    "# Create a covariance matrix with the desired correlation\n",
    "cov_matrix = np.array([[1, target_correlation],\n",
    "                       [target_correlation, 1]])\n",
    "\n",
    "# Perform Cholesky decomposition on the covariance matrix\n",
    "cholesky_matrix = np.linalg.cholesky(cov_matrix)\n",
    "\n",
    "for NUM_SAMPLE in [10, 50, 100, 1000, 10000, 50000]:\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Generate two random series of uncorrelated numbers\n",
    "    np.random.seed(42)  # Set a seed for reproducibility\n",
    "    correlated_series = np.random.multivariate_normal((0,0),[[1,target_correlation],[target_correlation,1]],NUM_SAMPLE)\n",
    "    \n",
    "    # Separate the correlated series into two individual series\n",
    "    series1 = correlated_series[:,0]\n",
    "    series2 = correlated_series[:,1]\n",
    "    \n",
    "    # Verify the correlation using numpy\n",
    "    computed_correlation = np.corrcoef(series1, series2)[0, 1]\n",
    "    print(f\"Computed correlation:{computed_correlation:.4f}\")\n",
    "    \n",
    "    random_numbers = series1*std_dev + mean\n",
    "    random_noises = series2*noise_std_dev + noise_mean\n",
    "    \n",
    "    \n",
    "    # Round the numbers to integers\n",
    "    data_sample = np.round(random_numbers+random_noises).astype(int)\n",
    "\n",
    "    sample_mean = np.mean(data_sample)\n",
    "    sample_std = np.std(data_sample)\n",
    "\n",
    "    # Define the confidence level and calculate the margin of error\n",
    "    confidence_level = 0.95\n",
    "    z_score = st.norm.ppf(confidence_level + (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_score * (sample_mean / sample_std)\n",
    "\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    print(\"Num.Sample: {}, Confidence Interval ({}%): ({:.4f}, {:.4f})\".format(NUM_SAMPLE, confidence_level * 100, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf09700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the Gaussian distribution\n",
    "mean = 50\n",
    "std_dev = 10\n",
    "\n",
    "noise_mean = 0\n",
    "noise_std_dev = 5\n",
    "\n",
    "# Set the desired correlation\n",
    "target_correlation = -0.5\n",
    "\n",
    "# Create a covariance matrix with the desired correlation\n",
    "cov_matrix = np.array([[1, target_correlation],\n",
    "                       [target_correlation, 1]])\n",
    "\n",
    "# Perform Cholesky decomposition on the covariance matrix\n",
    "cholesky_matrix = np.linalg.cholesky(cov_matrix)\n",
    "\n",
    "for NUM_SAMPLE in [10, 50, 100, 1000, 10000, 50000]:\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Generate two random series of uncorrelated numbers\n",
    "    np.random.seed(42)  # Set a seed for reproducibility\n",
    "    correlated_series = np.random.multivariate_normal((0,0),[[1,target_correlation],[target_correlation,1]],NUM_SAMPLE)\n",
    "    \n",
    "    # Separate the correlated series into two individual series\n",
    "    series1 = correlated_series[:,0]\n",
    "    series2 = correlated_series[:,1]\n",
    "    \n",
    "    # Verify the correlation using numpy\n",
    "    computed_correlation = np.corrcoef(series1, series2)[0, 1]\n",
    "    print(f\"Computed correlation:{computed_correlation:.4f}\")\n",
    "    \n",
    "    random_numbers = series1*std_dev + mean\n",
    "    random_noises = series2*noise_std_dev + noise_mean\n",
    "    \n",
    "    \n",
    "    # Round the numbers to integers\n",
    "    data_sample = np.round(random_numbers+random_noises).astype(int)\n",
    "\n",
    "    sample_mean = np.mean(data_sample)\n",
    "    sample_std = np.std(data_sample)\n",
    "\n",
    "    # Define the confidence level and calculate the margin of error\n",
    "    confidence_level = 0.95\n",
    "    z_score = st.norm.ppf(confidence_level + (1 - confidence_level) / 2)\n",
    "    margin_of_error = z_score * (sample_mean / sample_std)\n",
    "\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "\n",
    "    print(\"Num.Sample: {}, Confidence Interval ({}%): ({:.4f}, {:.4f})\".format(NUM_SAMPLE, confidence_level * 100, lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01604035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36746f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29faad6c",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = 0.2 # percent\n",
    "data_std = 1 # percent\n",
    "\n",
    "NUM_SAMPLE = 1000\n",
    "\n",
    "# Create a random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Generate normally distributed random numbers\n",
    "gaussian_numbers = rng.normal(data_mean, data_std, NUM_SAMPLE)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9adb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=dt.date(2018,1,1), end=dt.date.today(), freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_return = pd.Series(index=date_range[0:NUM_SAMPLE], data=[v/100 for v in gaussian_numbers])\n",
    "print(daily_return.head().append(daily_return.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=daily_return.plot(figsize=(25,6))\n",
    "ax.axhline(0, color='red', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204444c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_return = (daily_return+1).cumprod()\n",
    "ax=total_return.plot(figsize=(25,6))\n",
    "ax.axhline(1, color='red', linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e522e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5f893e",
   "metadata": {},
   "source": [
    "# Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d1a72",
   "metadata": {},
   "source": [
    "## Z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de84893d",
   "metadata": {},
   "source": [
    "### Null hypothesis: The mean return is zero\n",
    "### Alternative hypothesis: The mean return is not zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c787ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5039767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_daily_return = np.mean(daily_return*100)\n",
    "std_daily_return = np.std(daily_return*100)\n",
    "print(f\"Sample mean:{mean_daily_return:.4f}, Sample std:{std_daily_return:.4f}\")\n",
    "# Calculate the test statistic\n",
    "z_test_statistic = (mean_daily_return - 0) / (std_daily_return / np.sqrt(len(daily_return)))\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_test_statistic)))\n",
    "\n",
    "print(f\"Z-test statistic: {z_test_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.12f}\")\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc08799",
   "metadata": {},
   "source": [
    "### Null hypothesis: The mean return is 0.2%\n",
    "### Alternative hypothesis: The mean return is not 0.2%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ec964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_daily_return = np.mean(daily_return*100)\n",
    "std_daily_return = np.std(daily_return*100)\n",
    "print(f\"Sample mean:{mean_daily_return:.4f}, Sample std:{std_daily_return:.4f}\")\n",
    "# Calculate the test statistic\n",
    "z_test_statistic = (mean_daily_return - 0.2) / (std_daily_return / np.sqrt(len(daily_return)))\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 2 * (1 - norm.cdf(abs(z_test_statistic)))\n",
    "\n",
    "print(\"Z-test statistic: \", z_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c56c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242a4053",
   "metadata": {},
   "source": [
    "## F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2b5bd",
   "metadata": {},
   "source": [
    "### P-value: The p-value is the probability of obtaining an F-statistic as extreme as the observed value, assuming the null hypothesis is true. A small p-value (typically less than a predefined significance level) indicates strong evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347fa82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_test(group1, group2):\n",
    "    import scipy.stats\n",
    "    x = np.array(group1)\n",
    "    y = np.array(group2)\n",
    "\n",
    "    # Calculate the variance of each group\n",
    "    print(f\"Sample variance: Group1:{np.var(group1):.3f}, Group2:{np.var(group2):.3f}\")\n",
    "    f = np.var(group1, ddof=1)/np.var(group2, ddof=1)\n",
    "    df1 = x.size-1\n",
    "    df2 = y.size-1\n",
    "    p_value = scipy.stats.f.cdf(f, df1, df2)\n",
    "    return f, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61424268",
   "metadata": {},
   "source": [
    "### Null hypothesis: The two series of samples share same variance.\n",
    "### Alternative hypothesis: The two series of samples does not share same variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd848ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLE = 1000\n",
    "\n",
    "# Create a random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Generate normally distributed random numbers\n",
    "samples_1 = np.random.randn(NUM_SAMPLE)*0.5 + 10.5\n",
    "samples_2 = np.random.randn(NUM_SAMPLE)*0.5\n",
    "\n",
    "print(f\"Mean: Group1:{np.mean(samples_1):.2f}, Group2:{np.mean(samples_2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e353db",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_statistic, p_value = f_test(samples_1, samples_2)\n",
    "print(\"F-test statistic: \", f_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b70bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_statistic, p_value = f_test(samples_1-np.mean(samples_1), samples_2-np.mean(samples_2))\n",
    "print(\"F-test statistic: \", f_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLE = 1000\n",
    "\n",
    "# Create a random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Generate normally distributed random numbers\n",
    "samples_1 = np.random.randn(NUM_SAMPLE)*0.5 + 10.5\n",
    "samples_2 = np.random.randn(NUM_SAMPLE)*1.5\n",
    "\n",
    "print(f\"Mean: Group1:{np.mean(samples_1):.2f}, Group2:{np.mean(samples_2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41f1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test_statistic, p_value = f_test(samples_1, samples_2)\n",
    "print(\"F-test statistic: \", f_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4ce21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f69e376",
   "metadata": {},
   "source": [
    "## Chi-Square test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b38739",
   "metadata": {},
   "source": [
    "### Testing if the sample are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a859889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2, chi2_contingency\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f0dad",
   "metadata": {},
   "source": [
    "### Null hypothesis: The sample comes from normal distribution.\n",
    "### Alternative hypothesis: The sample does NOT follow normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d649513",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLE = 100000\n",
    "# Generate random samples from the log-normal distribution\n",
    "data_sample = np.random.normal(0.5, 1, NUM_SAMPLE)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean:{data_sample.mean():.3f}, std:{data_sample.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_Bins = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaed2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "# Plot the histogram\n",
    "plt.hist(data_sample, bins=Num_Bins,range=(-20, 30), edgecolor='black', alpha=0.75)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.grid()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the histogram of the stock returns\n",
    "hist_data, bins = np.histogram(data_sample, bins=Num_Bins)\n",
    "\n",
    "# Calculate expected frequencies assuming a normal distribution\n",
    "expected_freq = [NUM_SAMPLE * (norm.cdf(bins[i + 1], loc=data_sample.mean(), scale=data_sample.std()) - \n",
    "                               norm.cdf(bins[i], loc=data_sample.mean(), scale=data_sample.std())) for i in range(len(bins) - 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the chi-square test\n",
    "chi2_test_statistic, p_value, _, _ = chi2_contingency([hist_data, expected_freq])\n",
    "\n",
    "print(\"Chi-square test statistic: \", chi2_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118142f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71781e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLE = 10000\n",
    "# Generate random samples from the log-normal distribution\n",
    "data_sample = np.random.lognormal(0.5, 1, NUM_SAMPLE)*5\n",
    "data_sample = np.array([v for v in data_sample if v<50])\n",
    "print(f\"Mean:{data_sample.mean():.3f}, std:{data_sample.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5919f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "# Plot the histogram\n",
    "plt.hist(data_sample, bins=Num_Bins,range=(-1, 50), edgecolor='black', alpha=0.75)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "\n",
    "plt.grid()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08deb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the histogram of the stock returns\n",
    "hist_data, bins = np.histogram(data_sample, bins=50)\n",
    "\n",
    "# Calculate expected frequencies assuming a normal distribution\n",
    "expected_freq = [NUM_SAMPLE * (norm.cdf(bins[i + 1], loc=data_sample.mean(), scale=data_sample.std()) - \n",
    "                               norm.cdf(bins[i], loc=data_sample.mean(), scale=data_sample.std())) for i in range(len(bins) - 1)]\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2_test_statistic, p_value, _, _ = chi2_contingency([hist_data, expected_freq])\n",
    "\n",
    "print(\"Chi-square test statistic: \", chi2_test_statistic)\n",
    "print(\"P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e85dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114c523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
